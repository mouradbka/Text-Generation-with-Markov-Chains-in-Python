{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Generation with Markov Chains in Python\n",
    "============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['text/grimm_tales.txt', 'text/little_red_riding_hood.txt',\\\n",
    "         'text/robin_hood_prologue.txt']\n",
    "# files = ['text/grimm_tales.txt']\n",
    "text = ''\n",
    "for f in files:\n",
    "    with open(f, 'r') as f:\n",
    "        text += f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE GOLDEN BIRD\n",
      "\n",
      "A certain king had a beautiful garden, and in the garden stood a tree\n",
      "which bore golden apples. These apples were always counted, and\n"
     ]
    }
   ],
   "source": [
    "print(text[:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather as a Markov Chain\n",
    "-------------------------\n",
    "\n",
    "![alt text](images/markov_weather.png \"Weather\")\n",
    "\n",
    "Matrix representation (rows are current state, columns are next state):\n",
    "\n",
    "| | Sunny | Cloudy | Rainy |\n",
    "| --- | --- | --- | --- |\n",
    "| **Sunny** | 0.6 | 0.1 | 0.3 |\n",
    "| **Cloudy** | 0.3 | 0.3 | 0.4 |\n",
    "| **Rainy** | 0.3 | 0.2 | 0.5 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text as a Markov Chain\n",
    "----------------------\n",
    "\n",
    "**The cat ran over the dog.**\n",
    "\n",
    "![alt text](images/markov_text1.png \"Text\")\n",
    "\n",
    "Matrix representation (rows are current state, columns are next state):\n",
    "\n",
    "| | the | cat | ran | over | dog | . |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| **the** | 0 | 0.5 | 0 | 0 | 0.5 | 0 |\n",
    "| **cat** | 0 | 0 | 1 | 0 | 0 | 0 |\n",
    "| **ran** | 0 | 0 | 0 | 1 | 0 | 0 |\n",
    "| **over** | 1 | 0 | 0 | 0 | 0 | 0 |\n",
    "| **dog** | 0 | 0 | 0 | 0 | 0 | 1 |\n",
    "| **.** | 0 | 0 | 0 | 0 | 0 | 1 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define states as the distinct word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prince', 'assured', 'face', 'butcher', 'missing', 'brilliant', 'nocked', 'rows', 'hanged', 'branches', 'light', 'restingplace', 'whatsoever', 'conversation', 'swam', 'mouths', 'mouses', 'suspecting', 'boar', 'sausage', 'jingling', 'painted', 'flown', 'west', 'woes', 'envy', 'marks', 'entire', 'divided', 'walk', 'suck', 'unconsumed', 'cask', 'intention', 'nibbled', 'sounding', 'stuck', 'plaything', 'sin', 'month', 'dismay', 'talking', 'wetted', 'neigh', 'impatience', 'dismal', 'soldier', 'scarce', 'dangling', 'heard', 'belaboured', 'meddling', 'peacefully', 'help', 'relations', 'furs', 'nostrils', 'frolickd', 'advice', 'rolls', 'danger', 'roved', 'park', 'grease', 'impetuous', 'cur', 'crash', 'swim', 'handed', 'unbound', 'collapsed', 'height', 'seized', 'fun', 'push', 'scissorgrinder', 'willow', 'sinner', 'consequence', 'disenchanted', 'smiling', 'punishment', 'pot', 'enemys', 'snuff', 'gorged', 'happens', 'ranged', 'certainly', 'returning', 'dumpling', 'woefully', 'known', 'combed', 'cared', 'spindle', 'hairy', 'hark', 'settle', 'clockcase']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = re.sub(\"[^A-z,.!?'\\n ]+\", \"\", text) #cleaning characters to keep only the letters and punctuation. Important\n",
    "                                           #to keep space and \\n as well.  \n",
    "text = re.sub(\"([.,!?])\", r\" \\1 \", text) # we want to keep punctuations as token, so we replace with two spaces around. \n",
    "    #Here we are using a capture syntax https://www.lzone.de/examples/Python%20re.sub  \n",
    "    #need to put Parentheses around the squared brackets and then the '\\1'.\n",
    "    \n",
    "    #Needed to add the r\"..\" to indicate raw string to read the \\ correctly\n",
    "    \n",
    "tokens = text.lower().split()\n",
    "distinct_states = list(set(tokens))\n",
    "print(distinct_states[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "m = csr_matrix(\n",
    "    (len(distinct_states), len(distinct_states)), #Number of rows, number of columns. \n",
    "    dtype = int                                   #Defining the type of the elements. \n",
    "        )\n",
    "\n",
    "state_index = dict([(state, idx_num) for idx_num, state in enumerate(distinct_states)])\n",
    "    #We want numbers to indicate rows and column, so we make a dictionary. List can't be a dict key, so we use tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count transitions and fill in transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 s, sys: 3.91 ms, total: 29.3 s\n",
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(tokens)-1):\n",
    "    row = state_index[tokens[i]]\n",
    "    col = state_index[tokens[i+1]]\n",
    "    m[row, col]+=1\n",
    "#     m._set_intXint(row, col, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'capitalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'capitalize'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# We define randomly the first word we want to use. \n",
    "start_state_index  = np.random.randint(len(distinct_states))\n",
    "state = distinct_states[start_state_index]\n",
    "\n",
    "#We use num_sentences to keep track of how many sentences we want. \n",
    "num_sentences = 0\n",
    "\n",
    "#We capitalize the first word. \n",
    "output = state.capitalize()\n",
    "\n",
    "#We use this variable to remember when we need to capitalize or not. \n",
    "capitalize = False\n",
    "\n",
    "while num_sentences < 3:\n",
    "    #We start by taking all the potential following words for the first state we chose. \n",
    "    row = m[state_index[state], :]\n",
    "    probabilities = (row / row.sum()).toarray()[0] #normalizing the values\n",
    "#     probabilities =  tf.nn.softmax([float(x) for x in row.toarray()[0]])\n",
    "    \n",
    "#     if np.sum(probabilities) !=1.0:\n",
    "#         print('normalize', np.sum((row / row.sum()).toarray()[0]))\n",
    "#         print('tf softmax', np.sum(tf.nn.softmax([float(x) for x in row.toarray()[0]])))\n",
    "#         print('sc softmax', np.sum(scipy.special.softmax(row.toarray()[0])))\n",
    "        \n",
    "    next_state_index = np.random.choice( #allow to sample following a distrib.\n",
    "        len(distinct_states),\n",
    "        1,\n",
    "        p = probabilities #indicate the distrubution of each integer. \n",
    "    )\n",
    "    \n",
    "    next_state = distinct_states[next_state_index[0]]\n",
    "    \n",
    "    if next_state in ('.', '!', '?'):\n",
    "        output += next_state + '\\n\\n'\n",
    "        capitalize = True\n",
    "        num_sentences += 1\n",
    "        \n",
    "    elif next_state == ',':\n",
    "        output += next_state #no space\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        if capitalize:\n",
    "            output += next_state.capitalize()\n",
    "            capitalize = False\n",
    "        else:\n",
    "            output += ' ' + next_state\n",
    "\n",
    "    \n",
    "    state = next_state\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Word Markov Chain\n",
    "-------------------\n",
    "\n",
    "**The cat ran over the dog.**\n",
    "\n",
    "![alt text](images/markov_text2.png \"Text\")\n",
    "\n",
    "Matrix representation (rows are current state, columns are next state):\n",
    "\n",
    "| | the cat | cat ran | ran over | over the | the dog | dog. |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| **the cat**  | 0 | 1 | 0 | 0 | 0 | 0 |\n",
    "| **cat ran**  | 0 | 0 | 1 | 0 | 0 | 0 |\n",
    "| **ran over** | 0 | 0 | 0 | 1 | 0 | 0 |\n",
    "| **over the** | 0 | 0 | 0 | 0 | 1 | 0 |\n",
    "| **the dog**  | 0 | 0 | 0 | 0 | 0 | 1 |\n",
    "| **dog.**     | 0 | 0 | 0 | 0 | 0 | 1 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define states as consecutive token pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "tokens = text.lower().split()\n",
    "states = [ tuple(tokens[i:i+k]) for i in range(len(tokens) - k+1)] \n",
    "    #Need tuples because list can be a key in a dict.\n",
    "    \n",
    "distinct_states = list(set(states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and fill transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 17s, sys: 11.7 ms, total: 2min 17s\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "m = csr_matrix(\n",
    "    (len(distinct_states), len(distinct_states)), \n",
    "    dtype = int)\n",
    "\n",
    "state_index = dict( \n",
    "    [(state, idx_num) for idx_num, state in \\\n",
    "                   enumerate(distinct_states)])\n",
    "\n",
    "for i in range(len(tokens)-k):\n",
    "    state = tuple(tokens[i:i+k])\n",
    "    next_state = tuple(tokens[i+1:i+k+1])\n",
    "    row = state_index[state]\n",
    "    col = state_index[next_state]\n",
    "    m[row, col]+=1\n",
    "#     m._set_intXint(row, col, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", but also because he had poached upon the king's venison, washed down with draughts of ale of october brewing.\n",
      "\n",
      "Not only robin himself but all the gifts of the first giant.\n",
      "\n",
      "That is a very odd and uncommon name, is it a usual one in your family?\n",
      "\n",
      "\n",
      "CPU times: user 52.6 ms, sys: 1 µs, total: 52.6 ms\n",
      "Wall time: 51.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "\n",
    "start_state_index  = np.random.randint(len(distinct_states))\n",
    "state = distinct_states[start_state_index]\n",
    "\n",
    "num_sentences = 0\n",
    "output = ' '.join(state).capitalize()\n",
    "capitalize = False\n",
    "\n",
    "while num_sentences < 3:\n",
    "    \n",
    "    row = m[state_index[state], :]\n",
    "    probabilities = row / row.sum() #normalizing the values\n",
    "    probabilities = probabilities.toarray()[0] #[0] to get only the values. \n",
    "    \n",
    "    next_state_index = np.random.choice( #allow to sample following a distrib.\n",
    "        len(distinct_states),\n",
    "        1,\n",
    "        p = probabilities #indicate the distrubution of each integer. \n",
    "    )\n",
    "    \n",
    "    next_state = distinct_states[next_state_index[0]]\n",
    "    \n",
    "    if next_state[-1] in ('.', '!', '?'):\n",
    "#         print('punctuation ')\n",
    "        output += next_state[-1] + '\\n\\n'\n",
    "#         print(output)\n",
    "\n",
    "        capitalize = True\n",
    "        num_sentences += 1\n",
    "        \n",
    "    elif next_state[-1] == ',':\n",
    "#         print( ' , - ', next_state) \n",
    "        output += next_state[-1] #no space\n",
    "#         print(output)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        if capitalize:\n",
    "#             print('capita')\n",
    "            output += next_state[-1].capitalize()\n",
    "#             print(output)\n",
    "\n",
    "            capitalize = False\n",
    "        else:\n",
    "#             print('notmal')\n",
    "            output += ' ' + next_state[-1]\n",
    "#             print(output)\n",
    "\n",
    "    \n",
    "    state = next_state\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
